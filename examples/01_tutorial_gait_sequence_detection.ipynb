{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Gait Sequence Detection\n",
    "\n",
    "**Author:** Masoud Abedinifar\n",
    "\n",
    "**Last update:** Thu 14 Mar 2024\n",
    "\n",
    "## Learning objectives\n",
    "By the end of this tutorial:\n",
    "- You can load data from a recording that belongs to one of the available datasets,\n",
    "- Apply the Paraschiv-Ionescu gait sequence detection algorithm to accelerometer data.  \n",
    "- Visualize the results of gait sequence detection.  \n",
    "- Interpret the detected gait sequences for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paraschiv Gait Sequence Detection\n",
    "\n",
    "This example can be referenced by citing the package.\n",
    "\n",
    "The example illustrates how the Paraschiv-Ionescu gait sequence detection algorithm is used to detect gait sequences using body acceleration recorded with a triaxial accelerometer worn or fixed on the lower back. The gait sequence detection algorithm is implemented using [`ngmt.modules.gsd._paraschiv`](https://github.com/neurogeriatricskiel/NGMT/tree/main/ngmt/modules/gsd/_paraschiv.py). This algorithm is based on the research of Paraschiv-Ionescu et al ['1'-'2'].\n",
    "\n",
    "The algorithm detects gait sequences based on identified steps. It starts by loading the accelerometer data, which includes three columns corresponding to the acceleration signals across the x, y, and z axes, along with the sampling frequency of the data. To simplify the analysis, the norm of acceleration across the x, y, and z axes is computed. Next, the signal is resampled at a 40 Hz sampling frequency using interpolation. Smoothing is then applied through a Savitzky-Golay filter and a Finite Impulse Response (FIR) low-pass filter to remove noise and drifts from the signal. The continuous wavelet transform is applied to capture gait-related features, followed by additional smoothing using successive Gaussian-weighted filters. The processed data is then analyzed to detect gait sequences.\n",
    "\n",
    "The algorithm continues by identifying the envelope of the processed acceleration signal. Active periods of the signal are identified using the Hilbert envelope. The statistical distribution of the amplitude of the peaks in these active periods is used to derive an adaptive threshold. In case the Hilbert envelope algorithm fails to detect active periods, a fixed threshold value (0.15 g) is used for peak detection in the signal. Mid-swing peaks are detected based on this threshold. Pulse trains in the local maximum and minimum of the peaks are identified, with those having fewer than four steps filtered out. The intersection of pulse trains from local maximum and minimum peaks is detected as walking periods. These periods are then organized and grouped to update the start and end times of detected walking bouts.\n",
    "\n",
    "Next, the algorithm takes the last steps to detect walking bouts in the signal. For this purpose, walking bouts with five or more steps are detected, and their start and end times are added to the list. Walking labels are generated as an array of zeros, and the intervals corresponding to the walking bouts are labeled as 1. Groups of consecutive zeros in the walking labels are identified, and if breaks between walking bouts are less than three seconds, they are merged. The output is then constructed as a DataFrame containing gait sequence information in BIDS format. If gait sequences are found, the output is printed; otherwise, a message indicating that no gait sequences are detected is displayed.\n",
    "\n",
    "#### References\n",
    "['1'] Paraschiv-Ionescu et al. (2019). Locomotion and cadence detection using a single trunk-fixed accelerometer: validity for children with cerebral palsy in daily life-like conditions. Journal of NeuroEngineering and Rehabilitation, 16(1), 24. https://doi.org/10.1186/s12984-019-0494-z\n",
    "\n",
    "['2'] Paraschiv-Ionescu et al. (2020). Real-world speed estimation using a single trunk IMU: methodological challenges for impaired gait patterns. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. https://doi.org/10.1109/EMBC44109.2020.9176281\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "The necessary libraries such as numpy, matplotlib.pyplot, dataset, and Paraschiv-Ionescu gait sequence detection algorithms are imported. Make sure that you have all the required libraries and modules installed before running this code. You also may need to install the 'ngmt' library and its dependencies if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ngmt.datasets import mobilised\n",
    "from ngmt.modules.gsd import ParaschivIonescuGaitSequenceDetection\n",
    "from ngmt.config import cfg_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "To implement the Paraschiv-Ionescu gait sequence detection algorithm, we load example data from a congestive heart failure (CHF) cohort, which is publicly available on the Zenodo repository [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7547125.svg)](https://doi.org/10.5281/zenodo.7547125). \n",
    "\n",
    "The participant was assessed for 2.5 hours in the real-world while doing different daily life activities and also was asked to perform specific tasks such as outdoor walking, walking up and down a slope and stairs and moving from one room to another [`3`].\n",
    "\n",
    "#### Refertences\n",
    "\n",
    ".. [`3`] Mazz√†, Claudia, et al. \"Technical validation of real-world monitoring of gait: a multicentric observational study.\" BMJ open 11.12 (2021): e050785. http://dx.doi.org/10.1136/bmjopen-2021-050785\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'file_path' variable holds the absolute path to the data file\n",
    "file_path = (\n",
    "    r\"C:\\Users\\Project\\Desktop\\Gait_Sequence\\Mobilise-D dataset_1-18-2023\\CHF\\data.mat\"\n",
    ")\n",
    "\n",
    "# In this example, we use \"SU\" as tracking_system and \"LowerBack\" as tracked points.\n",
    "tracking_sys = \"SU\"\n",
    "tracked_points = {tracking_sys: [\"LowerBack\"]}\n",
    "\n",
    "# The 'mobilised.load_recording' function is used to load the data from the specified file_path\n",
    "recording = mobilised.load_recording(\n",
    "    file_name=file_path, tracking_systems=[tracking_sys], tracked_points=tracked_points\n",
    ")\n",
    "\n",
    "# Load lower back acceleration data\n",
    "acceleration_data = recording.data[tracking_sys][\n",
    "    [\"LowerBack_ACCEL_x\", \"LowerBack_ACCEL_y\", \"LowerBack_ACCEL_z\"]\n",
    "]\n",
    "\n",
    "# Get the corresponding sampling frequency directly from the recording\n",
    "sampling_frequency = recording.channels[tracking_sys][\n",
    "    recording.channels[tracking_sys][\"name\"] == \"LowerBack_ACCEL_x\"\n",
    "][\"sampling_frequency\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of the Data\n",
    "The raw acceleration data including components of x, y and z axis is represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time values in minutes\n",
    "# The 'time_in_minute' array represents time values in minutes, computed based on the length of 'acceleration_data' and 'sampling_frequency'.\n",
    "time_in_minute = np.arange(len(acceleration_data)) / (60 * sampling_frequency)\n",
    "\n",
    "# Create a figure with a specified size\n",
    "plt.figure(figsize=(22, 14))\n",
    "\n",
    "# Get colors for raw\n",
    "colors = cfg_colors[\"raw\"]\n",
    "\n",
    "# A loop is used to plot data for each accelerometer axis, applying different colors from the color map.\n",
    "for i in range(3):\n",
    "    plt.plot(\n",
    "        time_in_minute,\n",
    "        acceleration_data[f\"LowerBack_ACCEL_{chr(120 + i)}\"],\n",
    "        color=colors[i],\n",
    "        label=f\"Acc {'xyz'[i]}\",\n",
    "    )\n",
    "\n",
    "# Add labels and legends\n",
    "plt.xlabel(\"Time [minute]\", fontsize=20)\n",
    "plt.ylabel(\"Acceleration [g]\", fontsize=20)\n",
    "plt.legend(fontsize=18)\n",
    "\n",
    "# Add a title with a specified font size\n",
    "plt.title(\n",
    "    \"Accelerometer data from lower-back IMU sensor for CHF cohort\",\n",
    "    fontsize=30,\n",
    ")\n",
    "\n",
    "# Customize tick font sizes\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# Display a grid for reference\n",
    "plt.grid(visible=None, which=\"both\", axis=\"both\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in on specific time periods in the data, particularly the first 10 seconds, where clear blinks are evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time values based on the length of the data\n",
    "num_samples = len(acceleration_data)\n",
    "time_seconds = np.arange(num_samples) / sampling_frequency\n",
    "\n",
    "# Create a figure with the specified size\n",
    "plt.figure(figsize=(22, 14))\n",
    "\n",
    "# Plot acceleration data for each axis with time on the x-axis\n",
    "for i in range(3):\n",
    "    plt.plot(\n",
    "        time_seconds,\n",
    "        acceleration_data[f\"LowerBack_ACCEL_{chr(120 + i)}\"],\n",
    "        color=colors[i],\n",
    "        label=f\"Acc {'xyz'[i]}\",\n",
    "    )\n",
    "\n",
    "# Add labels and legends\n",
    "plt.xlabel(\"Time [seconds]\", fontsize=20)\n",
    "plt.ylabel(\"Acceleration [g]\", fontsize=20)\n",
    "plt.legend(fontsize=18)\n",
    "\n",
    "# Add a title\n",
    "plt.title(\n",
    "    \"Accelerometer data from lower-back IMU sensor for CHF cohort\",\n",
    "    fontsize=30,\n",
    ")\n",
    "\n",
    "# Customize font sizes\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# Set x-axis and y-axis limits for a specific duration (in seconds) and acceleration range\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(-1, 1.5)\n",
    "\n",
    "# Display a grid for reference\n",
    "plt.grid(visible=None, which=\"both\", axis=\"both\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Paraschiv-Ionescu Gait Sequence Detection Algorithm\n",
    "Now, we are running Paraschiv-Ionescu gait sequence detection algorithm from gsd module [`NGMT.ngmt.modules.gsd._paraschiv.ParaschivIonescuGaitSequenceDetection`](https://github.com/neurogeriatricskiel/NGMT/tree/main/ngmt/modules/gsd/_paraschiv.py) to detect gait sequences.\n",
    "\n",
    "In order to apply gait sequence detection algorithm, an instance of the ParaschivIonescuGaitSequenceDetection class is created using the constructor, `ParaschivIonescuGaitSequenceDetection()`. The `gsd` variable holds the instance, allowing us to access its methods. The inputs of the algorithm are as follows:\n",
    "\n",
    "- **Input Data:** `data` consist of accelerometer data (N, 3) for the x, y, and z axes in pandas Dataframe format.\n",
    "- **Sampling Frequency:** `sampling_freq_Hz` is the sampling frequency of the data, defined in Hz, with a default value of 100 Hz.\n",
    "- **Plot Results:** `plot_results`, if set to True, generates a plot showing the detected gait sequences on the data. The default is False. The onset is represented with the vertical green line and the grey area represents the duration of gait sequence detected by the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ParaschivIonescuGaitSequenceDetection class\n",
    "gsd = ParaschivIonescuGaitSequenceDetection(target_sampling_freq_Hz=40)\n",
    "\n",
    "# Call the gait sequence detection using gsd.detect\n",
    "gsd = gsd.detect(\n",
    "    data=acceleration_data, sampling_freq_Hz=sampling_frequency, plot_results=True, dt_data=None\n",
    ")\n",
    "\n",
    "# Gait sequences are stored in gait_sequences_ attribute of gsd\n",
    "gait_sequences = gsd.gait_sequences_\n",
    "\n",
    "# Add events to the recording as a dictionary including tracking system and events\n",
    "gait_sequence_events = gait_sequences\n",
    "recording.add_events(tracking_system=tracking_sys, new_events=gait_sequence_events)\n",
    "\n",
    "# Show events and their corresponding information\n",
    "print(recording.events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Visualization of the Detected Gait Sequences\n",
    "In the following, the raw data of the lower back sensor is plotted with the detected events. The events are plotted as vertical lines. The events are:\n",
    "- **Gait onset**: Start of the gait sequence\n",
    "- **Gait duration**: Duration of the gait sequence\n",
    "\n",
    "The onset is represented with the vertical green line and the grey area represents the duration of gait sequence detected by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access and print first detected gait sequence\n",
    "first_gait_sequence = recording.events[tracking_sys].iloc[0]\n",
    "print(\"First gait sequence:\\n\", first_gait_sequence)\n",
    "\n",
    "# Plot the raw data from the lower back\n",
    "fig, ax = plt.subplots(figsize=(22, 14))\n",
    "\n",
    "# Plot raw acceleration data\n",
    "for i in range(3):\n",
    "    ax.plot(\n",
    "        time_seconds,\n",
    "        acceleration_data[f\"LowerBack_ACCEL_{chr(120 + i)}\"],\n",
    "        color=colors[i],\n",
    "        label=f\"Acc {'xyz'[i]}\",\n",
    "    )\n",
    "\n",
    "# Plot the first element of gait sequences\n",
    "plt.axvline(first_gait_sequence[\"onset\"], color=\"g\", label=\"Gait onset\")\n",
    "ax.axvspan(\n",
    "    first_gait_sequence[\"onset\"],\n",
    "    first_gait_sequence[\"onset\"] + first_gait_sequence[\"duration\"],\n",
    "    alpha=0.2,\n",
    "    color=\"gray\",\n",
    "    label=\"Gait duration\",\n",
    ")\n",
    "\n",
    "# Customize plot\n",
    "start_limit = first_gait_sequence[\"onset\"] - 1\n",
    "end_limit = first_gait_sequence[\"onset\"] + first_gait_sequence[\"duration\"] + 1\n",
    "ax.set_xlim(start_limit, end_limit)\n",
    "ax.set_ylim(-1, 1.5)\n",
    "ax.set_xlabel(\"Time (seconds)\", fontsize=20)\n",
    "ax.set_ylabel(\"Acceleration (g)\", fontsize=20)\n",
    "ax.legend(loc=\"upper right\", fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ngmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
